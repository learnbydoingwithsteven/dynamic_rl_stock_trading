# Dynamic RL Stock Trading

This project provides a Streamlit application that simulates a live stock market and visualises how
multiple reinforcement learning (RL) agents adapt their strategies in real time. The app creates a
synthetic price series, lets agents trade on it, and surfaces detailed metrics such as per-step
rewards, win rates, and cumulative performance.

## Features

- ğŸ“ˆ **Real-time price simulation** using a configurable geometric random walk.
- ğŸ¤– **Multiple RL agents** (Q-Learning, SARSA, and a random baseline) trade simultaneously.
- ğŸ“Š **Live metrics dashboard** showing cumulative rewards, win rates, last actions, and more.
- âš™ï¸ **Customisable parameters** including drift, volatility, transaction cost, and refresh delay.

## Getting started

1. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

2. **Launch the Streamlit app**

   ```bash
   streamlit run app.py
   ```

3. Open the provided local URL in your browser. Adjust settings from the sidebar and click *Run
   Simulation* to watch the agents learn from the evolving market.

## Project structure

```
.
â”œâ”€â”€ app.py                         # Streamlit entry point
â”œâ”€â”€ dynamic_rl_stock_trading       # Simulation package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents.py                  # RL agent implementations
â”‚   â”œâ”€â”€ environment.py             # Price process and trading environment
â”‚   â””â”€â”€ simulation.py              # Simulation manager and helpers
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Notes

- Rewards and price changes are presented in relative (%) terms for easier comparison across runs.
- The simulation is intentionally lightweight for educational purposes; agents use tabular methods
  with discretised states rather than deep neural networks.
